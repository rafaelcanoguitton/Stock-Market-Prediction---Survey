\documentclass[conference]{IEEEtran}
\ifCLASSOPTIONcompsoc
  \usepackage[nocompress]{cite}
\else
  \usepackage{cite}
\fi
\ifCLASSINFOpdf
\else
\fi
\usepackage{multirow}
\usepackage{graphicx}
\begin{document}
\title{Stock Market Prediction using \\Artificial Intelligence}
\author{\IEEEauthorblockN{Rafael Isaac Cano Guitton}
\IEEEauthorblockA{School of Computer Science\\
Universidad Católica San Pablo \\
Arequipa, Perú \\
Email: rafael.cano@ucsp.edu.pe}
}
\maketitle
\begin{abstract}
Abstract not required for this presentation.
\end{abstract}
\IEEEpeerreviewmaketitle
\section{Introduction}
The stock market is a place which is a collection of markets where stocks of a firm are traded (bought and sold)\cite{M2018}.
Its behaviour is considered chaotic \cite{Singh2016} and it has always been ambiguous for investors
because of several influential factors. This unreliable behaviour make investors live the potential to lose big sums of money, or to treat
the stock market as gambling. There's a correlation between investment psychology and market behaviour. With a predictive model, we can give a 
solution for impulsive market selling and buying. Assuring a percentage of reliability in trading this impulsive action can be reduced. While there's many automated ways to assist investors' decisions
in a timely manner\cite{nabipour2020predicting}, it's not enough to adress this first issue.
\\\\
The main reason behind prediction is buying stocks that are likely to increase in price, and then selling stocks that are probably going to fall\cite{nabipour2020predicting}. 
Stock prices react to events related to business performance or overseas markets. Investors judge on the basis of technical analysis, such as company's charts\cite{Akita2016}.
\\\\
Now it is difficult to predict market trends and many AI approaches
have been investigated to predict them automatically. For example, investment simulation analysis with artificial
 markets\cite{Akita2016}.
\\\\
We'll focus on Machine Learning and Deep Learning:
\\\\
\begin{itemize}
  \item Machine Learning: It's a branch of AI that parses data, handles this data more efficiently and learns from that data. The main advantage is that, once
  the learning process is in a mature state, it can make informed decisions \cite{dey2016machine}. We use it in stock market prediction by learning patterns among big amounts of information.
  They can tackle the predicting task of price fluctuations to improve trading strategies \cite{nabipour2020predicting}.
  \\\\
  \item Deep Learning: It's a subfield of Machine Learning, so technically we can say that Deep Learning is Machine Learning.
  It's considered an evolution of Machine Learning, it structures algorithms in layers to create an Artificial Neural Network, this enables accurate decisions
  without help from humans. The stock market's instability and nonlinearity cause problems for data analysts to develop a predictive model \cite{nabipour2020predicting}. And thus we can use Neural Networks for a predictive model.
\end{itemize}
Artificial Neural Networks are specially useful since it's main usage is to recognize patterns. They're essentially simplified models of brains. In a brain, you have neurons, which are either activate or inactive,
and synapses, which connect the neurons together. The neurons are represented as simple booleans, and the synapses are represented by generally small numbers between negative one and one. The "weigth" of all the
synapses connected to a neuron determine it's state \cite{M2018}.
\\\\
Training a Neural Network generally takes a lot of time, but using one to make predictions is very fast.
\\\\
For our datasets we can use news articles, financial reports and posts from microblogs made by analysts \cite{Vargas2017}. Using Convolutional Neural Networks(CNN) and Recurrent Neural Networks(RNN) we can
catch semantics from text and context information. We can also use data from individual stocks, using information like stock symbol, stock series, stock date, previous closing, high, low, last, closing and average price of each stock.\cite{M2018}.
\\\\
The ample research literature, combined with the vast underlying models, tasks and training methods make it very
hard to identify the most appropriate approach or the most effective \cite{raghu2020survey}.
\\\\
And there's where our challenge resides. On this survey we aim to compare these techniques. We'll compare prediction values for certain stocks with real stock market behavior. Also we'll compare score based predictions for some approaches.
The purpose is to analyze current state of the art techniques for stock market accuracy\cite{Singh2016}.
% %\hfill mds
% %\hfill August 26, 2015
% %\subsection{Subsection Heading Here}
% %Subsection text here.
% %\subsubsection{Subsubsection Heading Here}
% Subsubsection text here.
% \section{Conclusion}
% The conclusion goes here.
\section{Related work}
ANN have been used in past decade in stock market prediction \cite{M2018}. ANN and HMM were proposed with the purpose to transform daily
stock values to independent group of prices as inputs to HMM \cite{nabipour2020predicting}. A common factor among current proposed models is that
an improvement to conventional neural networks is attempted. In Amir's study, nine ML methods (Decision Tree, Random Forest, Adaboost, XGBoost, SVC, NaïveBayes, KNN, Logistic Regression and ANN)
and two DL methods  (RNN and LSTM) were researched \cite{nabipour2020predicting} , putting special focus on performance.
They calculated indicators by stock trading values, using them as continuous data, and then converting indicators to binary data before using it. 
\\\\
In Amrita's study they used National Stock Exchange of India (NSE) and New York Stock Exchange (NYSE). Extracting day-wise closing price of stocks within different criteria, and then normaliznig data before feeding them to the
networks to train. They found similarities in patterns within those markets.
\\\\
There's also the textual information approach, in Vargas' proposal \cite{Vargas2017} they used 106.494 news articles
from Reuter's website, aiming to the topic of financial news. They found that using titles is more useful than the entire article for forecasting purposes,
so their proposed model only uses news titles. Now the proposed model uses only news from the day before the forecasting day, comparing them to models that use news from past day, week and month,
Vargas' model outperforms said models. On textual information approaches, Akita's proposal \cite{Akita2016} also uses financial news, but they also use numerical information. They use them to predict 10 companies' closing stock prices by regression.
Also learning correlation between companies. This since news from a company can have an effect in several companies' stock pricing within the same industry. 

\section{Predictive Models}
Taking in account research mentioned in related work, algorithms used for stock market prediction were clasified. This so we can have an overview of which techniques were used
and how these were applied. If there was preprocessing of data so we can know if that can have an impact.
\\\\
A classification based on dataset type was also made, this since several techniques were used in both cases but having  different results. 
\\\\
Therefore we'll have a look at models used in stock market prediction by:
\begin{itemize}
  \item Machine Learning Algorithms.
  \item Deep Learning Algorithms.
\end{itemize}
Also describing preprocessing and dataset type.
\begin{table}[]
  \caption{Models by Technique}
\begin{center}
  \begin{tabular}{|p{1.5cm}|p{2.1cm}|p{2.2cm}|p{1.5cm}|}
    \hline
    Technique                         & Models                                                & Preprocessing                                                 & Dataset type                                               \\ \hline
    Deep Learning    & CNN                                                   & Data Normalization                                            & \multicolumn{1}{c|}{\multirow{2}{*}{Textual \& Numerical}} \\ \cline{2-3}
                                      & RNN                                                   & Data Normalization \& Converting continuous data (indicators) & \multicolumn{1}{c|}{}                                      \\ \cline{2-4} 
                                      & (2D)²PCA + DNN                                        & -                                                             & \multirow{11}{*}{Numerical}                                \\ \cline{2-3}
                                      & (2D)²PCA + RBFNN                                      & -                                                             &                                                            \\ \cline{2-3}
                                      & DNN                                                   & -                                                             &                                                            \\ \cline{2-3}
                                      & MLP                                                   & Data Normalization                                            &                                                            \\ \cline{2-3}
                                      & LSTM                                                  & Data Normalization \& Converting continuous data (indicators) &                                                            \\ \cline{2-3}
                                      & ANN                                                   & -                                                             &                                                            \\ \cline{1-3}
    Machine Learning & KNN                                                   & Converting continuous data (indicators)      &                                                            \\ \cline{2-2}
                                      & Adaboost                                              &                                                               &                                                            \\ \cline{2-2}
                                      & XGBoost                                               &                                                               &                                                            \\ \cline{2-2}
                                      & SVC                                                   &                                                               &                                                            \\ \cline{2-2}
                                      & \begin{tabular}[c]{@{}c@{}}Naïve\\ Bayes\end{tabular} &                                                               &                                                            \\ \hline
    \end{tabular}
  \label{tab:comp}
  \end{center}
  \end{table}

\begin{figure}[htbp]
  \centerline{\includegraphics[scale=.45]{mapita.png}}
  \caption{Paper classification}
  \label{fig}
\end{figure}

\subsection{Machine Learning Algorithms}
A brief listing of Machine Learning Algorithms that were reviewed:
\subsubsection{K-Nearest Neighbors}
A method non-parametric for classification and regression, it's supervised and based on instances. It doesn't learn from a model explicitly, it memorizes
the instances of training that are used as a "knowledge base" for prediction phase.
\subsubsection{Adaptative Boosting}
It's a boosting technique that is used as an Ensemble Method.
\subsubsection{eXtreme Gradient Boosting}
It provides an efficient and effective implementation of the gradient boosting algorithm, designed to be computionally efficient
and highly effective.
\subsubsection{Support Vector Clasifier}
Supervised learning model, it's objective is to find a hyperplane in an N-dimensional space that
distinctly classifies the data points. It looks to maximize the margin between data points and the hyperplane.
\subsubsection{Naïve Bayes}
It's a probabilistic method that is based in Bayes' theorem, called Naive since given some additional simplifications that determine
the independance hipotesis of predict variables.
\\\\
There were several classification metrics across papers to evaluate performance of models,
among of which we can metion F1-Score, accuracy, receiver operating characteristics \cite{nabipour2020predicting},
Mape (Mean Absolute Percentage Error) \cite{M2018}, effectivenes of Paragraph Vector, effectivenes of LSTM \cite{Akita2016}, index prediction \cite{Vargas2017},
forecast values, Root Mean Square Error (RMSE), Hit Rate (HR) and Total Return (TR) \cite{Singh2016}.
\\\\
Each of the machine learning models have their limitations when it comes to solve the stock market prediction problem.
For training machine learning models in Nabipour's approach \cite{nabipour2020predicting}, they normalized features, randomly split 
the main dataset into train data and test data,fitting the models and evaluating them by validation data. When an extra layer to convert continuous data to binary
one based on the nature and property of the features there was a clear improvement. So continuous data has terrible performance on every model except some Deep Learning ones, so they're unviable with machine learning. Binary data on the other hand holds the aformentioned
improvement to the level of up to 83 percent. This since the layer that converts to it is able to convert non-stationary values to trend deterministic ones.
\\\\
Now despite it's clear performance disadvantage towards deep learning models, machine learning models have a better runtime performance. This due to the fact
that less computational power is required for prediction. This combined with binary data on Nabipour's approach \cite{nabipour2020predicting}, gets no less than 0.83 F1 score which would make it
a viable option.



\subsection{Deep Learning Algorithms}
A brief listing of Deep Learning Algorithms that were reviewed:

\subsubsection{Convolutional Neural Network}
It's an Artificial Neural Network with supervised learning that processes layers imitating the visual cortex
of the human eye to identify several characteristics on entries that definetly make it able to identify and see objects, these based in patterns.
\subsubsection{Recurrent Neural Network}
A class of neural networks that allow previous outputs to be used as inputs while having hidden states. They can process inputs of any length
\subsubsection{2-Directional 2-Dimensional Principal Component Analysis + Radial Basis Function NeuralNetwork}
The main idea behind 2DPCA is that it's based on 2D matrices as opposed to the standar PCA, it has higher accuracy. It is used for dimensionality reduction in
the researched proposals. It's output is fed to the RNN.
\subsubsection{2-Directional 2-Dimensional Principal Component Analysis + Deep Neural Network}
Same as last but it's output is instead fed to Dimension Neural Network, which is the simplest neural netowrk, it has some level of complexity, usually two layers.
\subsubsection{Multilayer Perceptron}
Also known as feed forward neural network, a simple example of a neural network. Each input neurons are linked to the succeeding hidden layer neuron
through a weighted matrix.
\subsubsection{Long Short-Term Memory}
Is a type of RNN capable of leaning order dependence in sequence prediction problems. A behaviour specially usefull to process our datasets. 
\subsubsection{Artificial Neural Network}
Usually single or multilayer nets whuch fully are fully connected together. By the rise in the number of hidden layers, it is able to form the network deeper.
\\\\
Since Deep Learning models are more robust on predicting tasks, their performance is always better than Machine Learning models.
On Akita's approach \cite{Akita2016}, they use Paragraph Vector to obtain the distributed representation by mapping variable length pieces of text to a fixed-length vector.
It's classified in two categories, Distributed Memory Model of Paragraph Vectors (PV-DM) and Dis-tributed Bag of Words version of Paragraph Vector (PV-DBOW). For their expermients they used a combination of Numerical and Textual
information, but they also compared it with only numerical information. It was able to get more profits in the four out of five industries and the total was also higher by 490 points. So it was effective to employ distributed representations
by using their aformentioned Paragraph Vector. They simulated real-world stock trading effectively doing Market Simulation. LSTM and RNN were tested on this artificial market and despite both being capable of considering time series data, LSTM
significantly outperformed Simple-RNN, this since LSTM has nondeterministic transactions. This meaning LSTM was able to capture the fluctuating time series changes well.
When using binary data on Nabipour's approach \cite{nabipour2020predicting}, although there were only 2 deep learning models used (RNN and LSTM), they showed a clear superiority for the predictive task, this time having RNN be superior to LSTM but with a smaller margin.
In Textual Information exclusively for Manuel's approach \cite{Vargas2017}, they made heavy comparisons between CNN and RNN based models. Using a classification of inputs from the dataset being word embedding input, sentence embedding input, bag of word, structure events tuple input, sum of each word in a document and event embedding.
Their results show that sentence embedding is better than word embedding, and that the RCNN proposed approach layering RNN and CNN has better structure than CNN for the index prediction task. This proposed model outperforms all baseline models with the expection of EB-CNN, this is likely ue to event embedding that is a more powerful method
to model the concent in news articles. This also shows that the architecture used for the prediction model is also an important factor.


\section{Conclusion}
Not required for this presentation.
\\\\
\ifCLASSOPTIONcompsoc
  \section*{Acknowledgments}
\else
  \section*{Acknowledgment}
\fi
Not required for this presentation.

\bibliographystyle{IEEEtran}
\bibliography{references}
\end{document}